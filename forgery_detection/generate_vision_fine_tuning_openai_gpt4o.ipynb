{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0da06ae8-f14b-45af-8460-ae5893d02bc4",
   "metadata": {},
   "source": [
    "# 1. 定义Prompt，读取文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34e79702-cd68-4331-aeed-61ca4bdb1b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SYSTEM_PROMPT = \"You are a rigorous and responsible image tampering (altering) detection expert. \" \\\n",
    "#     \"You can localize the exact tampered region and analyze your detection decision according to tampering clues at different levels. \" \\\n",
    "#     \"Assuming that you have detected this is a <FAKE> image and the manipulation type is [MANIPULATION_TYPE], \" \\\n",
    "#     \"the exact tampered region boundary is highlighted with color in this image (and your detection IS correct).\\n\" \\\n",
    "#     \"Please provide the chain-of-clues supporting your detection decision in the following style: \" \\\n",
    "#     \"# high-level semantic anomalies (such as content contrary to common sense, inciting and misleading content), \" \\\n",
    "#     \"# middle-level visual defects (such as traces of tampered region or boundary, lighting inconsistency, perspective relationships, and physical constraints) and \" \\\n",
    "#     \"# low-level pixel statistics (such as noise, color, textural, sharpness, and AI-generation fingerprint), \" \\\n",
    "#     \"where the high-level anomalies are significant doubts worth attention, and the middle-level and low-level findings are reliable evidence.\" \n",
    "\n",
    "\n",
    "REAL_ANALYSIS_TEXT_LIST = [\n",
    "    \"The following analysis affirms the authenticity of the image, with observations categorized into high-level semantic coherence, \" \\\n",
    "    \"middle-level visual consistency, and low-level pixel statistics.\\n\\n\" \\\n",
    "    \"# High-Level Semantic Coherence\\n\\n\" \\\n",
    "    \"1. Alignment with Common Sense\\n\\n\" \\\n",
    "    \"[DETAILED-CAPTION]\\n\" \\\n",
    "    \"The content is entirely plausible and aligns with real-world scenarios. The scene authentically reflects a natural and non-misleading setting.\\n\\n\" \\\n",
    "    \"# Middle-Level Visual Consistency\\n\\n\" \\\n",
    "    \"1. Absence of Boundary Traces or Irregularities\\n\\n\" \\\n",
    "    \"All regions of the image exhibit smooth transitions and natural continuity.\\n\\n\" \\\n",
    "    \"2. Coherent Lighting\\n\\n\" \\\n",
    "    \"The lighting across the image is consistent, with shadows, highlights, and reflections properly aligned to the light source.\\n\\n\" \\\n",
    "    \"3. Harmonious Perspective\\n\\n\" \\\n",
    "    \"The size, scale, and orientation of all elements are consistent with natural perspective rules. Spatial relationships between objects are logical.\\n\\n\" \\\n",
    "    \"4. Adherence to Physical Constraints\\n\\n\" \\\n",
    "    \"All interactions and arrangements of objects follow physical laws, such as gravity and balance.\\n\\n\" \\\n",
    "    \"# Low-Level Pixel Statistics\\n\\n\" \\\n",
    "    \"1. Uniform Color\\n\\n\" \\\n",
    "    \"The colors and tones are cohesive, with smooth gradients and consistent blending across the scene.\\n\\n\" \\\n",
    "    \"2. Homogeneous Texture and Sharpness\\n\\n\" \\\n",
    "    \"The texture and sharpness are evenly distributed, with no areas appearing artificially smoothed, grainy, or oversharpened.\",\n",
    "\n",
    "    \"The following analysis supports the authenticity of the image, categorizing observations into high-level semantic coherence, \" \\\n",
    "    \"middle-level visual consistency, and low-level pixel statistics.\\n\\n\" \\\n",
    "    \"# High-Level Semantic Coherence\\n\\n\" \\\n",
    "    \"## Consistency with Common Sense\\n\\n\" \\\n",
    "    \"[DETAILED-CAPTION]\\n\" \\\n",
    "    \"The image depicts an entirely plausible scenario that aligns with real-world expectations. The content reflects a natural and truthful setting with no misleading elements.\\n\\n\" \\\n",
    "    \"# Middle-Level Visual Consistency\\n\\n\" \\\n",
    "    \"## Consistent Lighting\\n\\n\" \\\n",
    "    \"The lighting across the image is coherent, with highlights and reflections consistently matching the direction of the light source.\\n\\n\" \\\n",
    "    \"## Compliance with Physical Constraints\\n\\n\" \\\n",
    "    \"The interactions and placements of objects adhere to physical laws, such as gravity and balance, ensuring that the scene is plausible in a real-world context.\\n\\n\" \\\n",
    "    \"## Consistent Perspective\\n\\n\" \\\n",
    "    \"The spatial relationships between elements are logical and free from distortion.\\n\\n\" \\\n",
    "    \"# Low-Level Pixel Statistics\\n\\n\" \\\n",
    "    \"## Cohesive Color Distribution\\n\\n\" \\\n",
    "    \"The colors and tones in the image are harmoniously distributed and align with the environment.\\n\\n\" \\\n",
    "    \"## Consistent Noise Patterns\\n\\n\" \\\n",
    "    \"The noise distribution across the image is uniform, with no abrupt changes or localized discrepancies that would indicate editing.\"\n",
    "]\n",
    "\n",
    "SYSTEM_PROMPT = \"The following analysis supports the authenticity of the image, with observations categorized into high-level semantic coherence, middle-level visual consistency, and low-level pixel statistics.\\\n",
    "# High-Level Semantic Coherence\\\n",
    "Consistency with Common Sense\\\n",
    "[DETAILED-CAPTION]\\\n",
    "The content is entirely plausible, aligning with real-world expectations. The scene reflects a natural, truthful setting with no misleading elements.\\\n",
    "# Middle-Level Visual Consistency\\\n",
    "Consistent Lighting\\\n",
    "\\\n",
    "The lighting throughout the image is coherent, with shadows, highlights, and reflections properly aligned with the light source, creating a realistic appearance.\\\n",
    "Compliance with Physical Constraints\\\n",
    "\\\n",
    "All interactions and placements of objects adhere to physical laws, such as gravity and balance, ensuring that the scene is plausible in the real world.\\\n",
    "Consistent Perspective\\\n",
    "\\\n",
    "The spatial relationships between objects are logically arranged, with no distortion, and the size, scale, and orientation of elements align with natural perspective rules.\\\n",
    "# Low-Level Pixel Statistics\\\n",
    "Cohesive Color Distribution\\\n",
    "\\\n",
    "The colors and tones in the image are smooth and cohesive, with no abrupt transitions, ensuring a natural blend across the scene.\\\n",
    "Uniform Texture and Sharpness\\\n",
    "\\\n",
    "The texture and sharpness are evenly distributed, with no areas appearing artificially smoothed, grainy, or oversharpened.\\\n",
    "Consistent Noise Patterns\\\n",
    "\\\n",
    "The noise distribution across the image is uniform, with no localized discrepancies or abrupt changes that could suggest editing or manipulation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58caa67a-b714-4096-852c-d085fb9f039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_path = \"./datasets/CASIA2\"\n",
    "image_pth = data_set_path + \"/images\"\n",
    "message = data_set_path + \"/tampering_analysis\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9d5ea18-025c-48f4-a6c4-36dd0e93d0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 获取image_pth目录下的所有文件\n",
    "image_files = [f for f in os.listdir(image_pth) if os.path.isfile(os.path.join(image_pth, f))]\n",
    "\n",
    "# 获取message目录下的所有文件，\n",
    "message_files = [f for f in os.listdir(message) if os.path.isfile(os.path.join(message, f))]\n",
    "\n",
    "# 检查message中是否有对应的文件\n",
    "for img in image_files:\n",
    "    img_name = os.path.splitext(img)[0]  # 去除扩展名进行比较\n",
    "    # 比较时忽略扩展名\n",
    "    if any(os.path.splitext(mf)[0] == img_name for mf in message_files):\n",
    "        # print(f\"File '{img}' found in both image_pth and message.\")\n",
    "        pass\n",
    "    else:\n",
    "        print(f\"File '{img}' not found in message.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a068485-6c3a-4a11-96a6-dd7669b0aa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个字典，将message_files中的文件名与对应的答案内容关联\n",
    "answer_dict = {}\n",
    "\n",
    "# 遍历message_files，读取每个文件的内容并填充到字典中\n",
    "for message_file in message_files:\n",
    "    message_path = os.path.join(message, message_file)  # 拼接消息文件的路径\n",
    "    with open(message_path, 'r') as file:\n",
    "        answer_content = file.read().strip()  # 假设每个文件包含一个文本答案\n",
    "    # 去除扩展名并将文件内容作为答案存入字典\n",
    "    answer_dict[os.path.splitext(message_file)[0]] = answer_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729e212f-a66c-4f63-8fd9-07fca01c6fb5",
   "metadata": {},
   "source": [
    "## 定义base64转换函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91c3440d-7198-42ee-9bad-df49995655c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "def encode_image(image, quality=100):\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')  # Convert to RGB\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\", quality=quality) \n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a467bda-d125-4fe8-8ef0-c3a87d9eb6b4",
   "metadata": {},
   "source": [
    "由于我们在进行视觉微调时会同时使用文本和图像，因此我们将构建这些消息以包含这两种内容类型。对于每个训练样本，有关图像的问题将作为用户消息呈现，而相应的答案将作为辅助消息提供。\n",
    "\n",
    "可以通过以下两种方式之一包含图像：\n",
    "\n",
    "- 作为HTTP URL，引用图像的位置。\n",
    "- 作为包含以base64编码的图像的数据 URL。\n",
    "```python\n",
    "{\n",
    "    \"messages\": \n",
    "    [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Use the image to answer the question.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"What is the title of this book?\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": \"data:image/jpeg;base64,<encoded_image>\"}}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "122d05c1-6864-4d0a-8f31-f622d8c318c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "ds_train = pd.DataFrame({\n",
    "    'image': image_files,\n",
    "    'question': [\"Analyze the image in a comprehensive and detailed manner.\"] * len(image_files),\n",
    "    'answer': [answer_dict.get(os.path.splitext(img)[0], \"Answer not found\") for img in image_files]  # 根据图像文件名获取对应答案\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa1a555d-4fa7-4a15-ad8c-4a0504e96e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tp_S_NNN_S_N_art00096_art00096_01004.tif</td>\n",
       "      <td>Analyze the image in a comprehensive and detai...</td>\n",
       "      <td>Through our analysis, we have discovered sever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tp_D_NRN_S_N_ind00064_ind00060_10945.jpg</td>\n",
       "      <td>Analyze the image in a comprehensive and detai...</td>\n",
       "      <td>We have found several clues, where high-level ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tp_S_NRN_M_N_sec00061_sec00061_11263.jpg</td>\n",
       "      <td>Analyze the image in a comprehensive and detai...</td>\n",
       "      <td>We have found several clues, where high-level ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tp_S_CNN_M_N_txt00006_txt00006_10839.jpg</td>\n",
       "      <td>Analyze the image in a comprehensive and detai...</td>\n",
       "      <td>We have identified the following clues, where ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tp_S_NNN_S_B_ani00014_ani00014_20058.jpg</td>\n",
       "      <td>Analyze the image in a comprehensive and detai...</td>\n",
       "      <td>We have identified the following clues, where ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5118</th>\n",
       "      <td>Tp_S_NRN_S_N_art00093_art00093_10486.tif</td>\n",
       "      <td>Analyze the image in a comprehensive and detai...</td>\n",
       "      <td>We have identified the following clues, where ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5119</th>\n",
       "      <td>Tp_D_NRN_S_N_sec00087_ani00037_00720.tif</td>\n",
       "      <td>Analyze the image in a comprehensive and detai...</td>\n",
       "      <td>After a thorough examination, we have identifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5120</th>\n",
       "      <td>Tp_S_NNN_M_N_ani00074_ani00074_10445.tif</td>\n",
       "      <td>Analyze the image in a comprehensive and detai...</td>\n",
       "      <td>We have identified the following clues, where ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5121</th>\n",
       "      <td>Tp_S_NRD_S_N_ind00011_ind00011_01309.tif</td>\n",
       "      <td>Analyze the image in a comprehensive and detai...</td>\n",
       "      <td>We have identified the following clues, where ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5122</th>\n",
       "      <td>Tp_S_CRN_M_N_cha10116_cha10116_12172.jpg</td>\n",
       "      <td>Analyze the image in a comprehensive and detai...</td>\n",
       "      <td>We have found several clues, where high-level ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5123 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         image  \\\n",
       "0     Tp_S_NNN_S_N_art00096_art00096_01004.tif   \n",
       "1     Tp_D_NRN_S_N_ind00064_ind00060_10945.jpg   \n",
       "2     Tp_S_NRN_M_N_sec00061_sec00061_11263.jpg   \n",
       "3     Tp_S_CNN_M_N_txt00006_txt00006_10839.jpg   \n",
       "4     Tp_S_NNN_S_B_ani00014_ani00014_20058.jpg   \n",
       "...                                        ...   \n",
       "5118  Tp_S_NRN_S_N_art00093_art00093_10486.tif   \n",
       "5119  Tp_D_NRN_S_N_sec00087_ani00037_00720.tif   \n",
       "5120  Tp_S_NNN_M_N_ani00074_ani00074_10445.tif   \n",
       "5121  Tp_S_NRD_S_N_ind00011_ind00011_01309.tif   \n",
       "5122  Tp_S_CRN_M_N_cha10116_cha10116_12172.jpg   \n",
       "\n",
       "                                               question  \\\n",
       "0     Analyze the image in a comprehensive and detai...   \n",
       "1     Analyze the image in a comprehensive and detai...   \n",
       "2     Analyze the image in a comprehensive and detai...   \n",
       "3     Analyze the image in a comprehensive and detai...   \n",
       "4     Analyze the image in a comprehensive and detai...   \n",
       "...                                                 ...   \n",
       "5118  Analyze the image in a comprehensive and detai...   \n",
       "5119  Analyze the image in a comprehensive and detai...   \n",
       "5120  Analyze the image in a comprehensive and detai...   \n",
       "5121  Analyze the image in a comprehensive and detai...   \n",
       "5122  Analyze the image in a comprehensive and detai...   \n",
       "\n",
       "                                                 answer  \n",
       "0     Through our analysis, we have discovered sever...  \n",
       "1     We have found several clues, where high-level ...  \n",
       "2     We have found several clues, where high-level ...  \n",
       "3     We have identified the following clues, where ...  \n",
       "4     We have identified the following clues, where ...  \n",
       "...                                                 ...  \n",
       "5118  We have identified the following clues, where ...  \n",
       "5119  After a thorough examination, we have identifi...  \n",
       "5120  We have identified the following clues, where ...  \n",
       "5121  We have identified the following clues, where ...  \n",
       "5122  We have found several clues, where high-level ...  \n",
       "\n",
       "[5123 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "119d0e47-56a7-4f43-b884-2570f42f0473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 4098\n",
      "Validation set size: 512\n",
      "Test set size: 513\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 假设ds_train是包含所有数据的原始数据集\n",
    "# 打乱数据并划分为训练集、验证集和测试集\n",
    "train_data, temp_data = train_test_split(ds_train, test_size=0.2, random_state=42)  # 80% 训练集\n",
    "validation_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)  # 10% 验证集，10% 测试集\n",
    "\n",
    "# 将划分后的数据集保存为新的变量\n",
    "ds_train_train = train_data\n",
    "ds_train_validation = validation_data\n",
    "ds_train_test = test_data\n",
    "\n",
    "# 打印每个数据集的大小\n",
    "print(f\"Training set size: {len(ds_train_train)}\")\n",
    "print(f\"Validation set size: {len(ds_train_validation)}\")\n",
    "print(f\"Test set size: {len(ds_train_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e1fd8b-35d2-4da7-9703-910fed57a55e",
   "metadata": {},
   "source": [
    "### 生成train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "974a7ccf-659a-40dd-be61-89e90ea7f361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4098it [00:12, 317.85it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# 构建训练集\n",
    "json_data = []\n",
    "\n",
    "for idx, example in tqdm(ds_train_train.iterrows()):\n",
    "    system_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": SYSTEM_PROMPT}]\n",
    "    }\n",
    "    \n",
    "    # 打开图像文件\n",
    "    image_path = os.path.join(image_pth, example['image'])  # 拼接图像路径\n",
    "    with Image.open(image_path) as img:\n",
    "        # 编码图像\n",
    "        encoded_image = encode_image(img, quality=50)\n",
    "\n",
    "    user_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": f\"Question [{idx}]: {example['question']}\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encoded_image}\"}}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    assistant_message = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": example[\"answer\"]}]\n",
    "    }\n",
    "\n",
    "    all_messages = [system_message] + [user_message, assistant_message]\n",
    "    \n",
    "    json_data.append({\"messages\": all_messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64488c2f-4262-44e4-be98-63f1118fdfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the JSON data to a file\n",
    "with open(\"forgery-detection-CASIA2-train.jsonl\", \"w\") as f:\n",
    "    for message in json_data:\n",
    "        json.dump(message, f)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad6fd48-4146-4366-b5e4-dc6c6679433d",
   "metadata": {},
   "source": [
    "### 生成test， validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06eb9025-d948-4fb4-a400-06a94431f312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "512it [00:01, 324.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# 构建验证集的JSON数据\n",
    "json_data = []\n",
    "\n",
    "for idx, example in tqdm(ds_train_validation.iterrows()):\n",
    "    system_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": SYSTEM_PROMPT}]\n",
    "    }\n",
    "    \n",
    "    # 打开图像文件\n",
    "    image_path = os.path.join(image_pth, example['image'])  # 拼接图像路径\n",
    "    with Image.open(image_path) as img:\n",
    "        # 编码图像\n",
    "        encoded_image = encode_image(img, quality=50)\n",
    "\n",
    "    user_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": f\"Question [{idx}]: {example['question']}\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encoded_image}\"}}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    assistant_message = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": example[\"answer\"]}]\n",
    "    }\n",
    "\n",
    "    all_messages = [system_message] + [user_message, assistant_message]\n",
    "    \n",
    "    json_data.append({\"messages\": all_messages})\n",
    "\n",
    "# 保存验证集的JSON数据到文件\n",
    "with open(\"forgery-detection-CASIA2-validation.jsonl\", \"w\") as f:\n",
    "    for message in json_data:\n",
    "        json.dump(message, f)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e598864-2dc8-4ef8-be44-676034e29075",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "513it [00:01, 328.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# 构建测试集的JSON数据\n",
    "json_data = []\n",
    "\n",
    "for idx, example in tqdm(ds_train_test.iterrows()):\n",
    "    system_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": SYSTEM_PROMPT}]\n",
    "    }\n",
    "    \n",
    "    # 打开图像文件\n",
    "    image_path = os.path.join(image_pth, example['image'])  # 拼接图像路径\n",
    "    with Image.open(image_path) as img:\n",
    "        # 编码图像\n",
    "        encoded_image = encode_image(img, quality=50)\n",
    "\n",
    "    user_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": f\"Question [{idx}]: {example['question']}\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encoded_image}\"}}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    assistant_message = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": example[\"answer\"]}]\n",
    "    }\n",
    "\n",
    "    all_messages = [system_message] + [user_message, assistant_message]\n",
    "    \n",
    "    json_data.append({\"messages\": all_messages})\n",
    "\n",
    "# 保存测试集的JSON数据到文件\n",
    "with open(\"forgery-detection-CASIA2-test.jsonl\", \"w\") as f:\n",
    "    for message in json_data:\n",
    "        json.dump(message, f)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6a05a8-e0bf-4331-8e38-3bffdcb32cef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54d2c82-bddd-4ab9-9052-008d69cf298a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
