{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be472ba7-63c1-4e5c-bd5e-f319aec26ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"You are a Vision Language Model specialized in interpreting visual data from chart images.\n",
    "Your task is to analyze the provided chart image and respond to queries with concise answers, usually a single word, number, or short phrase.\n",
    "The charts include a variety of types (e.g., line charts, bar charts) and contain colors, labels, and text.\n",
    "Focus on delivering accurate, succinct answers based on the visual information. Avoid additional explanation unless absolutely necessary.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1af351fc-6d06-42dc-b25b-93fb85ef005a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274350c343474554aa0ece4babbbc2ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/852 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15ae6dc107a4f44a0ba9ba6eeafaacb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00003-49492f364babfa44.parquet:   0%|          | 0.00/219M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3edc6a23b87c403f8d04323187e375ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00001-of-00003-7302bae5e425bbc7.parquet:   0%|          | 0.00/311M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "571c7f13649643cf8956666ecbd708fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00002-of-00003-194c9400785577a2.parquet:   0%|          | 0.00/315M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9165014391a41399889b9d20206cbdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-0f11003c77497969.parquet:   0%|          | 0.00/50.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "769a27de120e4a16b9ff95626393272e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-e2cd0b7a0f9eb20d.parquet:   0%|          | 0.00/68.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "999da906ed1f49489091bcc1949ed323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/28299 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926c60048c834821b4abfb0b10368bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating val split:   0%|          | 0/1920 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011ff51addb1401d9a425cdf01f3d6e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/2500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_id = \"HuggingFaceM4/ChartQA\"\n",
    "train_dataset, eval_dataset, test_dataset = load_dataset(dataset_id, split=[\"train[:10%]\", \"val[:10%]\", \"test[:10%]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80d313ee-2f27-4194-8173-c22c0785badd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'query', 'label', 'human_or_machine'],\n",
       "    num_rows: 2830\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8210040d-0083-4ba5-8914-8fcf7eb6941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(sample):\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": system_message}],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"image\": sample[\"image\"],\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": sample[\"query\"],\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": sample[\"label\"][0]}],\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71f3e21c-e8dd-44fb-9b22-522047b1782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = [format_data(sample) for sample in train_dataset]\n",
    "eval_dataset = [format_data(sample) for sample in eval_dataset]\n",
    "test_dataset = [format_data(sample) for sample in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6363c97-6e49-4c90-81b0-c444f8b03095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': 'You are a Vision Language Model specialized in interpreting visual data from chart images.\\nYour task is to analyze the provided chart image and respond to queries with concise answers, usually a single word, number, or short phrase.\\nThe charts include a variety of types (e.g., line charts, bar charts) and contain colors, labels, and text.\\nFocus on delivering accurate, succinct answers based on the visual information. Avoid additional explanation unless absolutely necessary.'}]},\n",
       " {'role': 'user',\n",
       "  'content': [{'type': 'image',\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=308x369>},\n",
       "   {'type': 'text',\n",
       "    'text': 'Is the rightmost value of light brown graph 58?'}]},\n",
       " {'role': 'assistant', 'content': [{'type': 'text', 'text': 'No'}]}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33b1d8ce-44c8-4f92-a97e-554e7efdef9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-03 12:10:37.787963: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-03 12:10:37.950165: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-03 12:10:37.988009: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.6/lib64:/opt/ros/humble/opt/rviz_ogre_vendor/lib:/opt/ros/humble/lib/x86_64-linux-gnu:/opt/ros/humble/lib\n",
      "2025-02-03 12:10:37.988017: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2025-02-03 12:10:38.012494: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-03 12:10:38.437962: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.6/lib64:/opt/ros/humble/opt/rviz_ogre_vendor/lib:/opt/ros/humble/lib/x86_64-linux-gnu:/opt/ros/humble/lib\n",
      "2025-02-03 12:10:38.438099: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.6/lib64:/opt/ros/humble/opt/rviz_ogre_vendor/lib:/opt/ros/humble/lib/x86_64-linux-gnu:/opt/ros/humble/lib\n",
      "2025-02-03 12:10:38.438106: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Idefics3ForConditionalGeneration, AutoProcessor\n",
    "\n",
    "model_id = \"HuggingFaceTB/SmolVLM-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "912fa67a-75d2-4426-ab62-8e246aa389bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2adc1d7bf2f43a788336089591de9ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/7.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b596dea1ecfc43a283578cfd7ebe1aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/4.49G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e7bc27bfd0404b96e31b57417c15df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/136 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a60a60f6e047ec86c7e5f121107fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processor_config.json:   0%|          | 0.00/68.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b597089691354e6781b1ac28c4af7bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json:   0%|          | 0.00/429 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ab5b16ab5b4ec0bf293afb386d540f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/486 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a95eb43539a495b8426206897af1341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/4.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce74d8a6c9e4b23a9c3a6b7ad7aed59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/801k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de16015715e4ea784bb0958389a88d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace0545e1ba64a4bbda26a640a1b83f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.52M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297e1cc6ce4e40739e969ff7dbb05646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/92.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a2a523f56245df8998ebabf046a623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/1.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some kwargs in processor config are unused and will not have any effect: image_seq_len. \n"
     ]
    }
   ],
   "source": [
    "model = Idefics3ForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    _attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfff49d9-224a-49ba-ba27-6c5aa5396d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': 'You are a Vision Language Model specialized in interpreting visual data from chart images.\\nYour task is to analyze the provided chart image and respond to queries with concise answers, usually a single word, number, or short phrase.\\nThe charts include a variety of types (e.g., line charts, bar charts) and contain colors, labels, and text.\\nFocus on delivering accurate, succinct answers based on the visual information. Avoid additional explanation unless absolutely necessary.'}]},\n",
       " {'role': 'user',\n",
       "  'content': [{'type': 'image',\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=422x359>},\n",
       "   {'type': 'text',\n",
       "    'text': 'How many values are below 40 in Unfavorable graph?'}]},\n",
       " {'role': 'assistant', 'content': [{'type': 'text', 'text': '6'}]}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b164f85-927d-44f1-bb9e-a7b1c1b0057a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': [{'type': 'image',\n",
       "    'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=422x359>},\n",
       "   {'type': 'text',\n",
       "    'text': 'How many values are below 40 in Unfavorable graph?'}]}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1][1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a3241e9-3dca-4d21-aa11-8ca98ce28eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=422x359>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1][1][\"content\"][0][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96d671eb-915b-429d-b44a-776440f91416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  generate_text_from_sample ( model, process, sample, max_new_tokens= 1024 , device= \"cuda\" ):\n",
    "     # 通过应用聊天模板准备文本输入\n",
    "    text_input = process.apply_chat_template( \n",
    "        sample[ 1 : 2 ], add_generation_prompt= True   # 使用没有系统消息的示例\n",
    "    ) \n",
    "\n",
    "    image_inputs = [] \n",
    "    image = sample[ 1 ][ \"content\" ][ 0 ][ \"image\" ]\n",
    "    if image.mode != \"RGB\" : \n",
    "        image = image.convert( \"RGB\" ) \n",
    "    image_inputs.append([image]) # 为模型准备输入\n",
    "    model_inputs = process( # text=[text_input], \n",
    "        text=text_input, \n",
    "        images=image_inputs, \n",
    "        return_tensors= \"pt\" , \n",
    "    ).to(device )# 将输入移动到指定设备# 使用模型生成文本\n",
    "    generated_ids = model.generate(**model_inputs, max_new_tokens=max_new_tokens) # 修剪生成的 id 以删除输入 id \n",
    "    trimmed_generated_ids = [out_ids[ len (in_ids) :] for in_ids, out_ids in zip (model_inputs.input_ids, generated_ids)] # 解码输出文本\n",
    "    output_text = processing.batch_decode( \n",
    "        trimmed_generated_ids, skip_special_tokens= True , clean_up_tokenization_spaces= False \n",
    "    ) \n",
    "    return output_text[ 0 ]   # 返回第一个解码的输出文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c28c257d-2884-406c-8900-42ec87da4c09",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "FlashAttention only supports Ampere GPUs or newer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_text_from_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m output\n",
      "Cell \u001b[0;32mIn[17], line 17\u001b[0m, in \u001b[0;36mgenerate_text_from_sample\u001b[0;34m(model, process, sample, max_new_tokens, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m image_inputs\u001b[38;5;241m.\u001b[39mappend([image]) \u001b[38;5;66;03m# 为模型准备输入\u001b[39;00m\n\u001b[1;32m     12\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m process( \u001b[38;5;66;03m# text=[text_input], \u001b[39;00m\n\u001b[1;32m     13\u001b[0m     text\u001b[38;5;241m=\u001b[39mtext_input, \n\u001b[1;32m     14\u001b[0m     images\u001b[38;5;241m=\u001b[39mimage_inputs, \n\u001b[1;32m     15\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m , \n\u001b[1;32m     16\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device )\u001b[38;5;66;03m# 将输入移动到指定设备# 使用模型生成文本\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 修剪生成的 id 以删除输入 id \u001b[39;00m\n\u001b[1;32m     18\u001b[0m trimmed_generated_ids \u001b[38;5;241m=\u001b[39m [out_ids[ \u001b[38;5;28mlen\u001b[39m (in_ids) :] \u001b[38;5;28;01mfor\u001b[39;00m in_ids, out_ids \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m (model_inputs\u001b[38;5;241m.\u001b[39minput_ids, generated_ids)] \u001b[38;5;66;03m# 解码输出文本\u001b[39;00m\n\u001b[1;32m     19\u001b[0m output_text \u001b[38;5;241m=\u001b[39m processing\u001b[38;5;241m.\u001b[39mbatch_decode( \n\u001b[1;32m     20\u001b[0m     trimmed_generated_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m , clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \n\u001b[1;32m     21\u001b[0m ) \n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ForgerySleuth/lib/python3.10/site-packages/transformers/generation/utils.py:2255\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2247\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2248\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2249\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2250\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2251\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2252\u001b[0m     )\n\u001b[1;32m   2254\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2255\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2256\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2260\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2262\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2263\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2265\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2266\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2267\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2268\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2269\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2274\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2275\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/ForgerySleuth/lib/python3.10/site-packages/transformers/generation/utils.py:3254\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3251\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   3253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[0;32m-> 3254\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3255\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3256\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/ForgerySleuth/lib/python3.10/site-packages/transformers/models/idefics3/modeling_idefics3.py:1195\u001b[0m, in \u001b[0;36mIdefics3ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, pixel_values, pixel_attention_mask, image_hidden_states, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1192\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1195\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpixel_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpixel_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1211\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/ForgerySleuth/lib/python3.10/site-packages/transformers/models/idefics3/modeling_idefics3.py:999\u001b[0m, in \u001b[0;36mIdefics3Model.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, pixel_values, pixel_attention_mask, image_hidden_states, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    996\u001b[0m patch_attention_mask \u001b[38;5;241m=\u001b[39m (patches_subgrid\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mbool()\n\u001b[1;32m    998\u001b[0m \u001b[38;5;66;03m# Get sequence from the vision encoder\u001b[39;00m\n\u001b[0;32m--> 999\u001b[0m image_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvision_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1000\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatch_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;66;03m# Modality projection & resampling\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m image_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnector(image_hidden_states)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/ForgerySleuth/lib/python3.10/site-packages/transformers/models/idefics3/modeling_idefics3.py:727\u001b[0m, in \u001b[0;36mIdefics3VisionTransformer.forward\u001b[0;34m(self, pixel_values, patch_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_flash_attention_2:\n\u001b[1;32m    725\u001b[0m     patch_attention_mask \u001b[38;5;241m=\u001b[39m _prepare_4d_attention_mask(patch_attention_mask, hidden_states\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 727\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    735\u001b[0m last_hidden_state \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    736\u001b[0m last_hidden_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_layernorm(last_hidden_state)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/ForgerySleuth/lib/python3.10/site-packages/transformers/models/idefics3/modeling_idefics3.py:517\u001b[0m, in \u001b[0;36mIdefics3Encoder.forward\u001b[0;34m(self, inputs_embeds, attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    510\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    511\u001b[0m         encoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    512\u001b[0m         hidden_states,\n\u001b[1;32m    513\u001b[0m         attention_mask,\n\u001b[1;32m    514\u001b[0m         output_attentions,\n\u001b[1;32m    515\u001b[0m     )\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 517\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mencoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/ForgerySleuth/lib/python3.10/site-packages/transformers/models/idefics3/modeling_idefics3.py:429\u001b[0m, in \u001b[0;36mIdefics3EncoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    426\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    428\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm1(hidden_states)\n\u001b[0;32m--> 429\u001b[0m hidden_states, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    436\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/ForgerySleuth/lib/python3.10/site-packages/transformers/models/idefics3/modeling_idefics3.py:346\u001b[0m, in \u001b[0;36mIdefics3VisionFlashAttention2.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m     key_states \u001b[38;5;241m=\u001b[39m key_states\u001b[38;5;241m.\u001b[39mto(target_dtype)\n\u001b[1;32m    344\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m value_states\u001b[38;5;241m.\u001b[39mto(target_dtype)\n\u001b[0;32m--> 346\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43m_flash_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_top_left_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flash_attn_uses_top_left_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    358\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_proj(attn_output)\n",
      "File \u001b[0;32m~/anaconda3/envs/ForgerySleuth/lib/python3.10/site-packages/transformers/modeling_flash_attention_utils.py:364\u001b[0m, in \u001b[0;36m_flash_attention_forward\u001b[0;34m(query_states, key_states, value_states, attention_mask, query_length, is_causal, dropout, position_ids, softmax_scale, sliding_window, use_top_left_mask, softcap, deterministic, cu_seq_lens_q, cu_seq_lens_k, max_length_q, max_length_k, target_dtype, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m     attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, attn_output\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m), attn_output\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mflash_attn_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msoftmax_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msoftmax_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcausal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_kwargs\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\n",
      "File \u001b[0;32m~/anaconda3/envs/ForgerySleuth/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py:1201\u001b[0m, in \u001b[0;36mflash_attn_func\u001b[0;34m(q, k, v, dropout_p, softmax_scale, causal, window_size, softcap, alibi_slopes, deterministic, return_attn_probs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mflash_attn_func\u001b[39m(\n\u001b[1;32m   1141\u001b[0m     q,\n\u001b[1;32m   1142\u001b[0m     k,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     return_attn_probs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1152\u001b[0m ):\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"dropout_p should be set to 0.0 during evaluation\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;124;03m    Supports multi-query and grouped-query attention (MQA/GQA) by passing in KV with fewer heads\u001b[39;00m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;124;03m    than Q. Note that the number of heads in Q must be divisible by the number of heads in KV.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;124;03m            pattern (negative means that location was dropped, nonnegative means it was kept).\u001b[39;00m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFlashAttnFunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m        \u001b[49m\u001b[43msoftmax_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcausal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m        \u001b[49m\u001b[43msoftcap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m        \u001b[49m\u001b[43malibi_slopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attn_probs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_grad_enabled\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    583\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/ForgerySleuth/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py:839\u001b[0m, in \u001b[0;36mFlashAttnFunc.forward\u001b[0;34m(ctx, q, k, v, dropout_p, softmax_scale, causal, window_size, softcap, alibi_slopes, deterministic, return_softmax, is_grad_enabled)\u001b[0m\n\u001b[1;32m    837\u001b[0m     k \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mpad(k, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m8\u001b[39m \u001b[38;5;241m-\u001b[39m head_size_og \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m8\u001b[39m])\n\u001b[1;32m    838\u001b[0m     v \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mpad(v, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m8\u001b[39m \u001b[38;5;241m-\u001b[39m head_size_og \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m8\u001b[39m])\n\u001b[0;32m--> 839\u001b[0m out_padded, softmax_lse, S_dmask, rng_state \u001b[38;5;241m=\u001b[39m \u001b[43m_wrapped_flash_attn_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43msoftmax_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcausal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_size_left\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_size_right\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43msoftcap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msoftcap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43malibi_slopes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malibi_slopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_softmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_softmax\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_grad:\n\u001b[1;32m    853\u001b[0m     ctx\u001b[38;5;241m.\u001b[39msave_for_backward(q, k, v, out_padded, softmax_lse, rng_state)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_ops.py:1116\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[0;32m-> 1116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_library/autograd.py:113\u001b[0m, in \u001b[0;36mmake_autograd_impl.<locals>.autograd_impl\u001b[0;34m(keyset, *args, **keyword_only_args)\u001b[0m\n\u001b[1;32m    111\u001b[0m     result \u001b[38;5;241m=\u001b[39m Generated\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;241m*\u001b[39margs, Metadata(keyset, keyword_only_args))  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_no_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMetadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeyword_only_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_library/autograd.py:40\u001b[0m, in \u001b[0;36mmake_autograd_impl.<locals>.forward_no_grad\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     38\u001b[0m keyset \u001b[38;5;241m=\u001b[39m metadata\u001b[38;5;241m.\u001b[39mkeyset\n\u001b[1;32m     39\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m metadata\u001b[38;5;241m.\u001b[39mkeyword_only_args\n\u001b[0;32m---> 40\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mredispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_after_autograd_keyset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_ops.py:721\u001b[0m, in \u001b[0;36mOpOverload.redispatch\u001b[0;34m(self, keyset, *args, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mredispatch\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, keyset, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 721\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mredispatch_boxed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_library/custom_ops.py:324\u001b[0m, in \u001b[0;36mCustomOpDef.register_kernel.<locals>.inner.<locals>.backend_impl\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbackend_impl\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# Checks the assumption that outputs cannot alias\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;66;03m# inputs or other outputs.\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     storages \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28mid\u001b[39m(tensor\u001b[38;5;241m.\u001b[39muntyped_storage())\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m iter_tensors(args, kwargs)\n\u001b[1;32m    322\u001b[0m     }\n\u001b[0;32m--> 324\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend_fns\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdevice_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     tuple_result \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_compile.py:32\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[1;32m     30\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m prior \u001b[38;5;241m=\u001b[39m _maybe_set_eval_frame(callback)\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    634\u001b[0m     _maybe_set_eval_frame(prior)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_library/custom_ops.py:367\u001b[0m, in \u001b[0;36mCustomOpDef.register_kernel.<locals>.inner.<locals>.wrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ForgerySleuth/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py:96\u001b[0m, in \u001b[0;36m_flash_attn_forward\u001b[0;34m(q, k, v, dropout_p, softmax_scale, causal, window_size_left, window_size_right, softcap, alibi_slopes, return_softmax)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;129m@_torch_custom_op_wrapper\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflash_attn::_flash_attn_forward\u001b[39m\u001b[38;5;124m\"\u001b[39m, mutates_args\u001b[38;5;241m=\u001b[39m(), device_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_flash_attn_forward\u001b[39m(\n\u001b[1;32m     83\u001b[0m     q: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m     return_softmax: \u001b[38;5;28mbool\u001b[39m\n\u001b[1;32m     94\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m     95\u001b[0m     q, k, v \u001b[38;5;241m=\u001b[39m [maybe_contiguous(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m (q, k, v)]\n\u001b[0;32m---> 96\u001b[0m     out, softmax_lse, S_dmask, rng_state \u001b[38;5;241m=\u001b[39m \u001b[43mflash_attn_gpu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfwd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43malibi_slopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43msoftmax_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcausal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwindow_size_left\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwindow_size_right\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43msoftcap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_softmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out, softmax_lse, S_dmask, rng_state\n",
      "\u001b[0;31mRuntimeError\u001b[0m: FlashAttention only supports Ampere GPUs or newer."
     ]
    }
   ],
   "source": [
    "output = generate_text_from_sample(model, processor, train_dataset[1])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a959089-3a26-45e8-9351-6b614932a25f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ForgerySleuth",
   "language": "python",
   "name": "forgerysleuth"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
